{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n\n<p style='text-align: ;'><span style=\"color: green; font-family: Segoe UI; font-size: 1.9em; font-weight: 300;\">Severstal: Steel Defect Detection</span></p>\n\n\n Steel is one of the most important building materials of modern times. Steel buildings are resistant to natural and man-made wear which has made the material ubiquitous around the world. To help make production of steel more efficient, this model will help identify defects.\n\n\n\n<img src=\"https://storage.googleapis.com/kaggle-competitions/kaggle/14241/logos/thumb76_76.png?t=2019-06-17-15-52-14\" width=\"700px\">","metadata":{}},{"cell_type":"markdown","source":"\n<p style='text-align: ;'><span style=\"color: green; font-family: Segoe UI; font-size: 1.9em; font-weight: 300;\">What is Xception model?</span></p>\n\nXception is a convolutional neural network that is 71 layers deep. You can load a pretrained version of the network trained on more than a million images from the ImageNet database . The pretrained network can classify images into 1000 object categories, such as keyboard, mouse, pencil, and many animals.\n\n\n<img src=\"https://gblobscdn.gitbook.com/assets%2F-LRrOFNeUGLZef_2NLZ0%2F-LeEDJgZ_Xj2uTEbaYKT%2F-LeEHZndr-UWea8jfQP8%2Fxception1.jpg?alt=media&token=d2a19b1a-1b5b-410d-90a5-7a5a993fe026\" width=\"800px\">\n\n\n\n","metadata":{}},{"cell_type":"markdown","source":"\n<p style='text-align: ;'><span style=\"color: green; font-family: Segoe UI; font-size: 1.9em; font-weight: 300;\">Data Description</span></p>\n\nIn this competition you will be predicting the location and type of defects found in steel manufacturing. Images are named with a unique ImageId. You must segment and classify the defects in the test set.\n\nEach image may have no defects, a defect of a single class, or defects of multiple classes. For each image you must segment defects of each class (ClassId = [1, 2, 3, 4]).\n\n\n<p style='text-align: ;'><span style=\"color: green; font-family: Segoe UI; font-size: 1.9em; font-weight: 300;\">Files</span></p>\n\n* train_images/ - folder of training images\n* test_images/ - folder of test images (you are segmenting and classifying these images)\n* train.csv - training annotations which provide segments for defects (ClassId = [1, 2, 3, 4])\n* sample_submission.csv - a sample submission file in the correct format; note, each ImageId 4 rows, one for each of the 4 defect classes","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport skimage.io\nimport os \nimport tqdm\nimport glob\nimport tensorflow \nimport warnings\nfrom tqdm import tqdm\nfrom sklearn.utils import shuffle\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.model_selection import train_test_split\nimport keras\nfrom skimage.io import imread, imshow\nfrom skimage.transform import resize\nfrom skimage.color import grey2rgb\nimport cv2\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import InputLayer, BatchNormalization, Dropout, Flatten, Dense, Activation, MaxPool2D, Conv2D\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.utils import to_categorical\nfrom keras import optimizers\nfrom tensorflow.keras.optimizers import Adam\nfrom keras.applications.nasnet import NASNetLarge, NASNetMobile\nfrom keras.callbacks import Callback,ModelCheckpoint,ReduceLROnPlateau\nfrom sklearn.preprocessing import OneHotEncoder,LabelEncoder\nfrom keras.utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Conv2D,Flatten,MaxPooling2D,Dropout\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import InputLayer, BatchNormalization, Dropout, Flatten, Dense, Activation, MaxPool2D\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.models import Sequential,load_model\nfrom keras.layers import Dense, Dropout\nfrom keras.wrappers.scikit_learn import KerasClassifier\nimport keras.backend as K\nfrom keras.applications.xception import Xception, preprocess_input\n#import tensorflow_addons as tfa\n#from tensorflow.keras.metrics import Metric\n#from tensorflow_addons.utils.types import AcceptableDTypes, FloatTensorLike\nprint(os.listdir('../input/severstal-steel-defect-detection'))\nfrom typeguard import typechecked\nfrom typing import Optional","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:41:46.416170Z","iopub.execute_input":"2022-03-09T18:41:46.416515Z","iopub.status.idle":"2022-03-09T18:41:46.429645Z","shell.execute_reply.started":"2022-03-09T18:41:46.416480Z","shell.execute_reply":"2022-03-09T18:41:46.428730Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/severstal-steel-defect-detection/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:41:48.774437Z","iopub.execute_input":"2022-03-09T18:41:48.774794Z","iopub.status.idle":"2022-03-09T18:41:49.143284Z","shell.execute_reply.started":"2022-03-09T18:41:48.774764Z","shell.execute_reply":"2022-03-09T18:41:49.142401Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:41:50.587234Z","iopub.execute_input":"2022-03-09T18:41:50.587620Z","iopub.status.idle":"2022-03-09T18:41:50.615161Z","shell.execute_reply.started":"2022-03-09T18:41:50.587578Z","shell.execute_reply":"2022-03-09T18:41:50.613745Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:41:56.069587Z","iopub.execute_input":"2022-03-09T18:41:56.069916Z","iopub.status.idle":"2022-03-09T18:41:56.075978Z","shell.execute_reply.started":"2022-03-09T18:41:56.069887Z","shell.execute_reply":"2022-03-09T18:41:56.074976Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import pandas_profiling as pp\npp.ProfileReport(df)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:21:24.164874Z","iopub.execute_input":"2022-03-09T18:21:24.165219Z","iopub.status.idle":"2022-03-09T18:21:32.714539Z","shell.execute_reply.started":"2022-03-09T18:21:24.165189Z","shell.execute_reply":"2022-03-09T18:21:32.713783Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df[\"ClassId\"].value_counts().plot(kind = 'bar')\ndf[\"ClassId\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:42:02.946574Z","iopub.execute_input":"2022-03-09T18:42:02.946917Z","iopub.status.idle":"2022-03-09T18:42:03.105108Z","shell.execute_reply.started":"2022-03-09T18:42:02.946887Z","shell.execute_reply":"2022-03-09T18:42:03.104183Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:42:07.910659Z","iopub.execute_input":"2022-03-09T18:42:07.910987Z","iopub.status.idle":"2022-03-09T18:42:07.916845Z","shell.execute_reply.started":"2022-03-09T18:42:07.910957Z","shell.execute_reply":"2022-03-09T18:42:07.915811Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"df.values","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:42:09.033363Z","iopub.execute_input":"2022-03-09T18:42:09.033763Z","iopub.status.idle":"2022-03-09T18:42:09.040924Z","shell.execute_reply.started":"2022-03-09T18:42:09.033729Z","shell.execute_reply":"2022-03-09T18:42:09.040010Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# cv2.imread() method loads an image from the specified file. If the image cannot be read (because of missing file, improper permissions, unsupported or invalid format) then this method returns an empty matrix.\n# cv2.IMREAD_COLOR: It specifies to load a color image. Any transparency of image will be neglected. It is the default flag. Alternatively, we can pass integer value 1 for this flag.\n# cv2.IMREAD_GRAYSCALE: It specifies to load an image in grayscale mode. Alternatively, we can pass integer value 0 for this flag.\n# cv2.IMREAD_UNCHANGED: It specifies to load an image as such including alpha channel. Alternatively, we can pass integer value -1 for this flag.","metadata":{}},{"cell_type":"code","source":"l1=[]\nl2=[] \nfor img,ClassId,EncodedPixels in tqdm(df.values):\n    image=cv2.imread(\"/kaggle/input/severstal-steel-defect-detection/train_images/{}\".format(img),cv2.IMREAD_COLOR)\n    image=cv2.resize(image,(120,120))\n    l1.append(image)\n    l2.append(ClassId)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:42:11.246096Z","iopub.execute_input":"2022-03-09T18:42:11.246433Z","iopub.status.idle":"2022-03-09T18:44:03.920498Z","shell.execute_reply.started":"2022-03-09T18:42:11.246401Z","shell.execute_reply":"2022-03-09T18:44:03.919669Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# cv2.imshow() method is used to display an image in a window. The window automatically fits to the image size.","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:23:36.695444Z","iopub.execute_input":"2022-03-09T18:23:36.695771Z","iopub.status.idle":"2022-03-09T18:23:36.699234Z","shell.execute_reply.started":"2022-03-09T18:23:36.695735Z","shell.execute_reply":"2022-03-09T18:23:36.698417Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"i = 1000\nprint(l2[i])\nplt.imshow(l1[i])\n","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:44:17.026515Z","iopub.execute_input":"2022-03-09T18:44:17.026883Z","iopub.status.idle":"2022-03-09T18:44:17.180880Z","shell.execute_reply.started":"2022-03-09T18:44:17.026850Z","shell.execute_reply":"2022-03-09T18:44:17.180020Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"encoder = LabelEncoder()\n\nX= np.array(l1)\nX = X/255\n\ny = encoder.fit_transform(l2)\ny = to_categorical(y)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:44:18.727652Z","iopub.execute_input":"2022-03-09T18:44:18.727967Z","iopub.status.idle":"2022-03-09T18:44:19.584231Z","shell.execute_reply.started":"2022-03-09T18:44:18.727940Z","shell.execute_reply":"2022-03-09T18:44:19.583388Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,stratify=y,shuffle=True)\nprint(\"x_train shape:\",X_train.shape)\nprint(\"x_test shape:\",X_test.shape)\nprint(\"y_train shape:\",y_train.shape)\nprint(\"y_test shape:\",y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:44:20.428921Z","iopub.execute_input":"2022-03-09T18:44:20.429254Z","iopub.status.idle":"2022-03-09T18:44:21.209193Z","shell.execute_reply.started":"2022-03-09T18:44:20.429222Z","shell.execute_reply":"2022-03-09T18:44:21.208356Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"base_model = tf.keras.applications.Xception(input_shape=(120,120,3),include_top=False,weights=\"imagenet\")","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:44:21.984031Z","iopub.execute_input":"2022-03-09T18:44:21.984360Z","iopub.status.idle":"2022-03-09T18:44:26.831389Z","shell.execute_reply.started":"2022-03-09T18:44:21.984330Z","shell.execute_reply":"2022-03-09T18:44:26.830448Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Freezing Layers\n\nfor layer in base_model.layers[:-1]:\n    layer.trainable=False\n","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:44:26.833273Z","iopub.execute_input":"2022-03-09T18:44:26.833683Z","iopub.status.idle":"2022-03-09T18:44:26.843046Z","shell.execute_reply.started":"2022-03-09T18:44:26.833603Z","shell.execute_reply":"2022-03-09T18:44:26.842113Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Building Model\n\nmodel=Sequential()\nmodel.add(base_model)\nmodel.add(Dropout(0.5))\nmodel.add(Flatten())\nmodel.add(Dense(256,activation=\"relu\"))\nmodel.add(Dropout(0.3))\nmodel.add(BatchNormalization())\nmodel.add(Dense(512,activation=\"relu\"))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(128,activation=\"relu\"))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(256,activation=\"relu\"))\nmodel.add(Dense(4,activation=\"softmax\"))","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:44:26.844929Z","iopub.execute_input":"2022-03-09T18:44:26.845265Z","iopub.status.idle":"2022-03-09T18:44:27.227847Z","shell.execute_reply.started":"2022-03-09T18:44:26.845231Z","shell.execute_reply":"2022-03-09T18:44:27.226997Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Model Summary\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:44:27.231087Z","iopub.execute_input":"2022-03-09T18:44:27.231431Z","iopub.status.idle":"2022-03-09T18:44:27.250292Z","shell.execute_reply.started":"2022-03-09T18:44:27.231402Z","shell.execute_reply":"2022-03-09T18:44:27.249580Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils import plot_model\nfrom IPython.display import Image\nplot_model(model, to_file='convnet.png', show_shapes=True,show_layer_names=True)\nImage(filename='convnet.png')","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:44:27.672617Z","iopub.execute_input":"2022-03-09T18:44:27.672946Z","iopub.status.idle":"2022-03-09T18:44:28.121253Z","shell.execute_reply.started":"2022-03-09T18:44:27.672916Z","shell.execute_reply":"2022-03-09T18:44:28.120278Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"'''\ndef f1_score(y_true, y_pred): #taken from old keras source code\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives / (predicted_positives + K.epsilon())\n    recall = true_positives / (possible_positives + K.epsilon())\n    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n    return f1_val\n'''","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:44:29.020622Z","iopub.execute_input":"2022-03-09T18:44:29.020965Z","iopub.status.idle":"2022-03-09T18:44:29.027407Z","shell.execute_reply.started":"2022-03-09T18:44:29.020934Z","shell.execute_reply":"2022-03-09T18:44:29.026157Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"METRICS = [\n      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n      tf.keras.metrics.Precision(name='precision'),\n      tf.keras.metrics.Recall(name='recall'),  \n      tf.keras.metrics.AUC(name='auc')\n]","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:44:30.843208Z","iopub.execute_input":"2022-03-09T18:44:30.843547Z","iopub.status.idle":"2022-03-09T18:44:30.875681Z","shell.execute_reply.started":"2022-03-09T18:44:30.843503Z","shell.execute_reply":"2022-03-09T18:44:30.874832Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"lrd = ReduceLROnPlateau(monitor = 'val_loss',patience = 20,verbose = 1,factor = 0.50, min_lr = 1e-10)\n\nmcp = ModelCheckpoint('model.h5')\n\nes = EarlyStopping(verbose=1, patience=20)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:44:32.854038Z","iopub.execute_input":"2022-03-09T18:44:32.854489Z","iopub.status.idle":"2022-03-09T18:44:32.864661Z","shell.execute_reply.started":"2022-03-09T18:44:32.854451Z","shell.execute_reply":"2022-03-09T18:44:32.863651Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='Adam', loss='categorical_crossentropy',metrics=METRICS)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:44:34.035495Z","iopub.execute_input":"2022-03-09T18:44:34.035927Z","iopub.status.idle":"2022-03-09T18:44:34.056727Z","shell.execute_reply.started":"2022-03-09T18:44:34.035882Z","shell.execute_reply":"2022-03-09T18:44:34.055603Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"aug = ImageDataGenerator(\n    rotation_range=10,\n    zoom_range=0.15,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    shear_range=0.15,\n    horizontal_flip=False,\n    vertical_flip=False,\n    fill_mode=\"nearest\")","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:44:35.185790Z","iopub.execute_input":"2022-03-09T18:44:35.186136Z","iopub.status.idle":"2022-03-09T18:44:35.191429Z","shell.execute_reply.started":"2022-03-09T18:44:35.186097Z","shell.execute_reply":"2022-03-09T18:44:35.190394Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"%time\nhistory = model.fit(aug.flow(X_train,y_train,batch_size=128),epochs=15,validation_data=(X_test,y_test),verbose=1,callbacks=[lrd,mcp,es])","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:44:36.550268Z","iopub.execute_input":"2022-03-09T18:44:36.550623Z","iopub.status.idle":"2022-03-09T18:50:01.208465Z","shell.execute_reply.started":"2022-03-09T18:44:36.550583Z","shell.execute_reply":"2022-03-09T18:50:01.204646Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"#%% PLOTTING RESULTS (Train vs Validation FOLDER 1)\n'''\ndef Train_Val_Plot(acc,val_acc,loss,val_loss,auc,val_auc,precision,val_precision,f1,val_f1):\n    \n    fig, (ax1, ax2,ax3,ax4,ax5) = plt.subplots(1,5, figsize= (20,5))\n    fig.suptitle(\" MODEL'S METRICS VISUALIZATION \")\n\n    ax1.plot(range(1, len(acc) + 1), acc)\n    ax1.plot(range(1, len(val_acc) + 1), val_acc)\n    ax1.set_title('History of Accuracy')\n    ax1.set_xlabel('Epochs')\n    ax1.set_ylabel('Accuracy')\n    ax1.legend(['training', 'validation'])\n\n\n    ax2.plot(range(1, len(loss) + 1), loss)\n    ax2.plot(range(1, len(val_loss) + 1), val_loss)\n    ax2.set_title('History of Loss')\n    ax2.set_xlabel('Epochs')\n    ax2.set_ylabel('Loss')\n    ax2.legend(['training', 'validation'])\n    \n    ax3.plot(range(1, len(auc) + 1), auc)\n    ax3.plot(range(1, len(val_auc) + 1), val_auc)\n    ax3.set_title('History of AUC')\n    ax3.set_xlabel('Epochs')\n    ax3.set_ylabel('AUC')\n    ax3.legend(['training', 'validation'])\n    \n    ax4.plot(range(1, len(precision) + 1), precision)\n    ax4.plot(range(1, len(val_precision) + 1), val_precision)\n    ax4.set_title('History of Precision')\n    ax4.set_xlabel('Epochs')\n    ax4.set_ylabel('Precision')\n    ax4.legend(['training', 'validation'])\n    \n    ax5.plot(range(1, len(f1) + 1), f1)\n    ax5.plot(range(1, len(val_f1) + 1), val_f1)\n    ax5.set_title('History of F1-score')\n    ax5.set_xlabel('Epochs')\n    ax5.set_ylabel('F1 score')\n    ax5.legend(['training', 'validation'])\n\n\n    plt.show()\n    \n\nTrain_Val_Plot(history.history['accuracy'],history.history['val_accuracy'],\n               history.history['loss'],history.history['val_loss'],\n               history.history['auc'],history.history['val_auc'],\n               history.history['precision'],history.history['val_precision'],\n               history.history['f1_score'],history.history['val_f1_score']\n              )\n              \n'''\n","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:28:58.150163Z","iopub.execute_input":"2022-03-09T18:28:58.150501Z","iopub.status.idle":"2022-03-09T18:28:58.737691Z","shell.execute_reply.started":"2022-03-09T18:28:58.150463Z","shell.execute_reply":"2022-03-09T18:28:58.736759Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"Evaluate = model.evaluate(X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:50:40.495269Z","iopub.execute_input":"2022-03-09T18:50:40.495629Z","iopub.status.idle":"2022-03-09T18:50:42.955898Z","shell.execute_reply.started":"2022-03-09T18:50:40.495593Z","shell.execute_reply":"2022-03-09T18:50:42.954981Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"prediction = model.predict(X_test)\nclasses_x = (np.argmax(prediction,axis=1))","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:50:45.704900Z","iopub.execute_input":"2022-03-09T18:50:45.705235Z","iopub.status.idle":"2022-03-09T18:50:48.508281Z","shell.execute_reply.started":"2022-03-09T18:50:45.705202Z","shell.execute_reply":"2022-03-09T18:50:48.507394Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"y_test1 = np.argmax(y_test,axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:50:52.213845Z","iopub.execute_input":"2022-03-09T18:50:52.214187Z","iopub.status.idle":"2022-03-09T18:50:52.218443Z","shell.execute_reply.started":"2022-03-09T18:50:52.214157Z","shell.execute_reply":"2022-03-09T18:50:52.217443Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"cm = confusion_matrix(classes_x,y_test1)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:50:59.249797Z","iopub.execute_input":"2022-03-09T18:50:59.250146Z","iopub.status.idle":"2022-03-09T18:50:59.260722Z","shell.execute_reply.started":"2022-03-09T18:50:59.250116Z","shell.execute_reply":"2022-03-09T18:50:59.259720Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.metrics import ConfusionMatrixDisplay\n\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm,\n                              display_labels=[0,1,2,3])\n\n\n# NOTE: Fill all variables here with default values of the plot_confusion_matrix\ndisp = disp.plot()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:51:00.427833Z","iopub.execute_input":"2022-03-09T18:51:00.428193Z","iopub.status.idle":"2022-03-09T18:51:00.624296Z","shell.execute_reply.started":"2022-03-09T18:51:00.428160Z","shell.execute_reply":"2022-03-09T18:51:00.623437Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"df_submission = pd.read_csv('../input/severstal-steel-defect-detection/sample_submission.csv')\nprint(df_submission.shape)\ndf_submission.head(100)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T19:01:16.665855Z","iopub.execute_input":"2022-03-09T19:01:16.666238Z","iopub.status.idle":"2022-03-09T19:01:16.698066Z","shell.execute_reply.started":"2022-03-09T19:01:16.666203Z","shell.execute_reply":"2022-03-09T19:01:16.697197Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"model.save(\"steel_model1.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:51:25.822892Z","iopub.execute_input":"2022-03-09T18:51:25.823294Z","iopub.status.idle":"2022-03-09T18:51:26.297592Z","shell.execute_reply.started":"2022-03-09T18:51:25.823260Z","shell.execute_reply":"2022-03-09T18:51:26.296694Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'steel_model.h5')","metadata":{"execution":{"iopub.status.busy":"2022-03-09T17:34:47.318482Z","iopub.execute_input":"2022-03-09T17:34:47.318791Z","iopub.status.idle":"2022-03-09T17:34:47.326104Z","shell.execute_reply.started":"2022-03-09T17:34:47.318761Z","shell.execute_reply":"2022-03-09T17:34:47.325176Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}